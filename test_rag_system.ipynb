{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9ddecd-5d20-49cb-be13-88b9f146b0e1",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9eb380-158e-4bcf-9b5b-debc11312b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from ast import literal_eval\n",
    "from math import floor\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.collections.classes.config import (\n",
    "    Property, DataType\n",
    ")\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from llmlingua import PromptCompressor\n",
    "from jinja2 import Template\n",
    "\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas import evaluate, RunConfig\n",
    "from ragas.metrics import LLMContextRecall, LLMContextPrecisionWithReference, LLMContextPrecisionWithoutReference, AnswerRelevancy, AnswerCorrectness, AnswerSimilarity, Faithfulness\n",
    "from datasets import Dataset  \n",
    "\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8e6b90-114a-4adf-88fe-b439a737cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_path = os.getenv(\"ENCODER_MODEL\")\n",
    "llm_name = os.getenv(\"LLM\")\n",
    "prompts_folder = os.getenv(\"PROMPTS_FOLDER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439c7bb8-3b0e-4cf8-8180-572f64591e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19180/3776595078.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = SentenceTransformerEmbeddings(model_name=embedding_model_path, model_kwargs={\"trust_remote_code\":True, 'device': 'cuda'})\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformerEmbeddings(model_name=embedding_model_path, model_kwargs={\"trust_remote_code\":True, 'device': 'cuda'})\n",
    "compressor = PromptCompressor(model_name='microsoft/llmlingua-2-xlm-roberta-large-meetingbank', use_llmlingua2=True)\n",
    "wv_client = weaviate.connect_to_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b29009-7e0a-4f97-a09a-7f4b4d2d34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(\n",
    "    model=llm_name,\n",
    "    temperature=0,\n",
    "    base_url=f\"http://localhost:11434\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e38080e-6369-4762-9d33-52573c375e17",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "74888507-5c06-4062-b3b3-744080813025",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooksProcessor:\n",
    "    def __init__(self, wv_client, embedding_model):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.wv_client = wv_client\n",
    "\n",
    "    def create_collection_if_not_exists(self, collection_name):\n",
    "        if not self.wv_client.collections.exists(collection_name):\n",
    "            self.wv_client.collections.create(\n",
    "                name=collection_name,\n",
    "                properties=[\n",
    "                    Property(name=\"chunk\", data_type=DataType.TEXT),\n",
    "                    Property(name=\"book_name\", data_type=DataType.TEXT),\n",
    "                    Property(name=\"chunk_num\", data_type=DataType.INT)\n",
    "                ],\n",
    "                #vectorizer_config=wvc.config.Configure.Vectorizer.none()\n",
    "                #vectorizer_config=[\n",
    "                    #Configure.NamedVectors.text2vec_ollama(\n",
    "                    #    name=\"book_vectorizer\",\n",
    "                    #    source_properties=[\"book_chunks\"],\n",
    "                    #    api_endpoint=\"http://ollama:11434\",\n",
    "                    #    model=self.embedding_model_name,\n",
    "                    #    vector_index_config=Configure.VectorIndex.hnsw(\n",
    "                    #        distance_metric=VectorDistances.COSINE\n",
    "                    #    )\n",
    "                    #)\n",
    "                #]\n",
    "            )\n",
    "        return self.wv_client.collections.get(collection_name)\n",
    "\n",
    "    def split_book(self, book_text, chunk_size, chunk_overlap):\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap\n",
    "        )\n",
    "        return [i.page_content for i in splitter.create_documents([book_text])]\n",
    "\n",
    "    def process_book(self, book_name, book_txt):\n",
    "        if self.wv_client.collections.exists(book_name + '_medium_chunks'):\n",
    "            print(\"Book already exists\")\n",
    "            return\n",
    "        chunk_configs = [\n",
    "        #    ('_big_chunks', 3000, 1000),\n",
    "            ('_medium_chunks', 1000, 100),\n",
    "        #    ('_small_chunks', 400, 50)\n",
    "        ]\n",
    "        \n",
    "        for suffix, chunk_size, overlap in chunk_configs:\n",
    "            collection = self.create_collection_if_not_exists(book_name + suffix)\n",
    "            chunks = self.split_book(book_txt, chunk_size, overlap)\n",
    "            embeddings = self.embedding_model.embed_documents(['search_document: ' + i for i in chunks])\n",
    "            question_objs = []\n",
    "\n",
    "            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "                question_objs.append(wvc.data.DataObject(\n",
    "                    properties= {\n",
    "                        \"chunk\": chunk,\n",
    "                        \"book_name\": book_name,\n",
    "                        \"chunk_num\": i\n",
    "                    },\n",
    "                    vector=embedding\n",
    "                ))\n",
    "            collection.data.insert_many(question_objs)\n",
    "\n",
    "    def delete_book(self, book_name: str) -> None:\n",
    "        \"\"\"\n",
    "        Delete all collections associated with a book.\n",
    "        \"\"\"\n",
    "        for suffix in ['_big_chunks', '_medium_chunks', '_small_chunks']:\n",
    "            collection_name = book_name + suffix\n",
    "            if self.wv_client.collections.exists(collection_name):\n",
    "                try:\n",
    "                    self.wv_client.collections.delete(collection_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error deleting collection {collection_name}: {e}\")\n",
    "        print(f\"Successfully deleted collections for {book_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177d7b36-0f29-407b-ac1c-51956d2dfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor.delete_book('Sherlock_Study_in_Scarlet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73cdcc39-bcfe-437c-b113-12b6765bc084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book already exists\n"
     ]
    }
   ],
   "source": [
    "processor = BooksProcessor(wv_client, embedding_model)\n",
    "with open('Sherlock_Study_in_Scarlet.txt', 'r', encoding='utf8') as file:\n",
    "    text = file.read()\n",
    "processor.process_book('Sherlock_Study_in_Scarlet', text)\n",
    "#processor.delete_book('Sherlock_Study_in_Scarlet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fe5ee36-798b-498f-b4a0-feaed5f6d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_type = '_medium_chunks'\n",
    "book_name='Sherlock_Study_in_Scarlet'\n",
    "book = wv_client.collections.get(book_name + collection_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f17c5b7e-24d6-4b54-867a-f40e7ade7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for item in book.iterator():\n",
    "    docs.append(Document(metadata={\"file_name\": item.properties['book_name']},\n",
    "                         page_content=item.properties['chunk']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52298804-910e-49d4-ab28-49b5943744fe",
   "metadata": {},
   "source": [
    "# RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d9491686-47c1-4f62-8380-922a23ec86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Search:\n",
    "    def __init__(self, wv_client, embedding_model):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.wv_client = wv_client\n",
    "        self.multiplier_mapping = {'_big_chunks': 0.7, '_medium_chunks': 1, '_small_chunks': 1.9}\n",
    "        #self._load_prompt_template()\n",
    "\n",
    "    def search(self, query, book_name):\n",
    "        collection_type = '_medium_chunks'\n",
    "        book = self.wv_client.collections.get(book_name + collection_type)\n",
    "        \n",
    "        total_count = book.aggregate.over_all(total_count=True).total_count\n",
    "        chunks_to_retrieve = floor(np.maximum(self.multiplier_mapping[collection_type] * np.log(total_count), 1))\n",
    "        \n",
    "        embedding = self.embedding_model.embed_query('search_query: ' + query)\n",
    "        response = book.query.near_vector(near_vector=list(embedding), limit=chunks_to_retrieve, return_metadata=wvc.query.MetadataQuery(certainty=True))\n",
    "        relevant_chunks = response.objects#sorted(response.objects, key=lambda x: x.properties['chunk_num'])\n",
    "        relevant_text = '\\n'.join([f\"\\nCHUNK {i.properties['chunk_num']}\\n\" + i.properties['chunk'].strip() for i in relevant_chunks])\n",
    "        return relevant_text\n",
    "\n",
    "class RAGSystem:\n",
    "    def __init__(self, wv_client, embedding_model, compressor, llm_name, prompts_folder, compression_rate=0.75):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.searcher = Search(wv_client, self.embedding_model)\n",
    "        self.compression_rate = compression_rate\n",
    "        self.compressor = compressor\n",
    "        self.llm = OllamaLLM(\n",
    "            model=llm_name,\n",
    "            temperature=0,\n",
    "            base_url=f\"http://localhost:11434\"\n",
    "        )\n",
    "        with open(os.path.join(prompts_folder, 'final_prompt.j2')) as f:\n",
    "            self._template = f.read()\n",
    "\n",
    "    def query(self, query: str, book_names: List[str], \n",
    "             dialogue_history: Optional[List[Dict[str, str]]] = None) -> str:\n",
    "        dialogue_history = dialogue_history or []\n",
    "        compressed_contexts = []\n",
    "        \n",
    "        for book_name in book_names:\n",
    "            context = self.searcher.search(query, book_name)\n",
    "            if context:\n",
    "                compressed = self.compressor.compress_prompt(\n",
    "                    context,\n",
    "                    rate=self.compression_rate,\n",
    "                    force_tokens=['\\n', '?', '.', '!', 'CHUNK']\n",
    "                )['compressed_prompt']\n",
    "                compressed_contexts.append(f\"From {book_name}:\\n{compressed}\")\n",
    "        \n",
    "        if not compressed_contexts:\n",
    "            return \"No relevant information found.\"\n",
    "\n",
    "        final_prompt = Template(self._template).render(\n",
    "            contexts=compressed_contexts,\n",
    "            dialogue_history=dialogue_history,\n",
    "            query=query\n",
    "        )\n",
    "        \n",
    "        return compressed_contexts, self.llm.invoke(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "383e4db2-d0bc-4236-a725-f9fd7a696621",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = RAGSystem(wv_client, embedding_model, compressor, llm_name=llm_name, prompts_folder=prompts_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac74ec0-3f3c-4414-b181-f087466768a3",
   "metadata": {},
   "source": [
    "# Ragas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cfe06b-0543-4132-a33f-9fabc0a5f8b9",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9897aaa-c6cf-4e87-aabe-5acddc24b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "# generator_llm = LangchainLLMWrapper(llm)\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24dbfd32-fe6d-4688-a6fa-8759ee5ec28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsetgenerator = TestsetGenerator(generator_llm, embedding_model=generator_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91a3e680-a282-4294-8fb5-092033a6a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testsetgenerator_.knowledge_graph = joblib.load('testsetgenerator_kg.pkl')\n",
    "# testsetgenerator_.persona_list = joblib.load('testsetgenerator_pl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f8ff0f3-3cb8-461b-a44b-a3e9ea84e005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestsetGenerator(llm=LangchainLLMWrapper(langchain_llm=ChatOpenAI(...)), embedding_model=LangchainEmbeddingsWrapper(embeddings=HuggingFaceEmbeddings(...)), knowledge_graph=KnowledgeGraph(nodes: 0, relationships: 0), persona_list=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsetgenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f3a91-5695-45f4-ae2d-e7cfc1f108ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 100\n",
    "testset = testsetgenerator.generate_with_langchain_docs(docs, testset_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b376c-0fd5-4f38-bdf0-5e4d43d20a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_pd = testset.to_pandas()\n",
    "testset_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd11cd-d698-4046-b8ce-03b6d36c07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_pd.to_csv('synthetic_data_ragas_4o-mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9e94d-b407-4ed4-a837-baf1c785f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(testsetgenerator.knowledge_graph, 'testsetgenerator_kg_llama_4o-mini.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43aca8-4597-4d23-a243-c49f4c49db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(testsetgenerator.persona_list, 'testsetgenerator_pl_llama_4o-mini.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64422d-337e-4901-ba32-4732b19df1c2",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f131b188-1ea6-4b82-b721-bac86815cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_pd = pd.read_csv('synthetic_data_ragas_4o-mini.csv', converters={'reference_contexts': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aa8acfa1-44d8-4d98-ab86-b53a6893c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_pd['reference_contexts'] = testset_pd['reference_contexts'].apply(lambda lst: [s[38:] for s in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7d4d3460-a5f1-4290-95ca-735a893eb61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalset_pd = pd.DataFrame({'user_input':testset_pd['user_input'],\n",
    "                           'retrieved_contexts': [''] * len(testset_pd),\n",
    "                           'reference_contexts': testset_pd['reference_contexts'],\n",
    "                           'response': [''] * len(testset_pd),\n",
    "                           'reference': testset_pd['reference']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896e22e-523e-49e9-8bce-cebe3e81919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalset_pd[['retrieved_contexts', 'response']] = evalset_pd.apply(lambda row: rag.query(\n",
    "    query=row['user_input'],\n",
    "    book_names=['Sherlock_Study_in_Scarlet'],\n",
    "    dialogue_history=[]\n",
    "), axis=1, result_type ='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5a666c65-4f7d-467f-b70e-cf4f13d22919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalset_pd.to_csv('synthetic_full_data_ragas_4o-mini_llama-3.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab70ebb-f871-4fb0-9541-77208e58cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evalset_pd = pd.read_csv('synthetic_full_data_ragas_4o-mini_llama-3.2.csv', converters={'retrieved_contexts': literal_eval, 'reference_contexts': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f3d7a41-a4fc-4eac-9e11-2694ecfbaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = RunConfig(timeout=120, max_wait = 180, max_workers= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650693e9-7e9a-45ae-9aea-8e6f9e79bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_result = evaluate(\n",
    "  dataset=Dataset.from_pandas(evalset_pd),\n",
    "  metrics=[\n",
    "      LLMContextRecall(llm=generator_llm),\n",
    "      LLMContextPrecisionWithReference(llm=generator_llm),\n",
    "      LLMContextPrecisionWithoutReference(llm=generator_llm),\n",
    "      AnswerCorrectness(llm=generator_llm, embeddings=generator_embeddings),\n",
    "      AnswerRelevancy(llm=generator_llm, embeddings=generator_embeddings),\n",
    "      AnswerSimilarity(embeddings=generator_embeddings),\n",
    "      Faithfulness(llm=generator_llm)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "426b2ecc-cc27-4a20-8e1b-5ea5468e4c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.7348, 'llm_context_precision_with_reference': 0.9796, 'llm_context_precision_without_reference': 0.9400, 'answer_correctness': 0.5003, 'answer_relevancy': 0.6371, 'semantic_similarity': 0.8422, 'faithfulness': 0.8400}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf00a9f3-623d-45b3-85cd-d18cfe1ea900",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreset_pd = score_result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21170f27-a8d7-42b1-8dcf-f3f1b5b0abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoreset_pd.to_csv('synthetic_score_data_ragas_4o-mini_llama-3.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71554797-e399-49d3-be84-5b63e400c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreset_pd = pd.read_csv('synthetic_score_data_ragas_4o-mini_llama-3.2.csv', converters={'retrieved_contexts': literal_eval, 'reference_contexts': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "feb2987e-8f4d-4aba-b1ba-4c09e558ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_scoreset_pd = scoreset_pd[(scoreset_pd.iloc[:, 5:] > 0.5).mean(axis=1) == 1].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54f5754e-0b82-4280-bff3-d33b2b637f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len good dataset: 32\n"
     ]
    }
   ],
   "source": [
    "print('Len good dataset:', len(filter_scoreset_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a4a0c8f-b240-4028-a5cb-f97726e778ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context_recall                             0.734760\n",
       "llm_context_precision_with_reference       0.979592\n",
       "llm_context_precision_without_reference    0.940000\n",
       "answer_correctness                         0.500302\n",
       "answer_relevancy                           0.637103\n",
       "semantic_similarity                        0.842173\n",
       "faithfulness                               0.840015\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreset_pd.iloc[:, 5:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bd40070-fd42-4786-9942-29ef073a8222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context_recall                             0.908073\n",
       "llm_context_precision_with_reference       1.000000\n",
       "llm_context_precision_without_reference    1.000000\n",
       "answer_correctness                         0.651239\n",
       "answer_relevancy                           0.845944\n",
       "semantic_similarity                        0.882017\n",
       "faithfulness                               0.894918\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_scoreset_pd.iloc[:, 5:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1492b07c-06de-4aec-81e2-2b935e5b9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score_pd(scoreset_pd, idx):\n",
    "    print('user_input:', scoreset_pd.iloc[idx]['user_input'], '\\n')\n",
    "    print('retrieved_contexts:', scoreset_pd.iloc[idx]['retrieved_contexts'], '\\n')\n",
    "    print('reference_contexts:', scoreset_pd.iloc[idx]['reference_contexts'], '\\n')\n",
    "    print('response:', scoreset_pd.iloc[idx]['response'], '\\n')\n",
    "    print('reference:', scoreset_pd.iloc[idx]['reference'], '\\n')\n",
    "    \n",
    "    print('context_recall =', scoreset_pd.iloc[idx]['context_recall'])\n",
    "    print('llm_context_precision_with_reference =', scoreset_pd.iloc[idx]['llm_context_precision_with_reference'])\n",
    "    print('llm_context_precision_without_reference =', scoreset_pd.iloc[idx]['llm_context_precision_without_reference'])\n",
    "    print('answer_correctness =', scoreset_pd.iloc[idx]['answer_correctness'])\n",
    "    print('answer_relevancy =', scoreset_pd.iloc[idx]['answer_relevancy'])\n",
    "    print('semantic_similarity =', scoreset_pd.iloc[idx]['semantic_similarity'])\n",
    "    print('faithfulness =', scoreset_pd.iloc[idx]['faithfulness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "524c2b31-2cbf-4cb8-a766-7aed2aabb8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_input: What can we learn about the character Hope and the themes of hope and sacrifice in the context of the murder case involving Enoch Drebber and Joseph Stangerson? \n",
      "\n",
      "retrieved_contexts: ['From Sherlock_Study_in_Scarlet:\\n\\nCHUNK 328\\n “The public,” said “have lost sensational treat through\\n sudden death of man Hope, suspected of murder of Mr.\\n Enoch Drebber and of Mr. Joseph Stangerson. details of case\\n probably be never known now, informed upon good\\n authority crime was result of old standing and romantic\\n feud, in love and Mormonism bore part. seems both\\n victims belonged younger to Latter Day Saints,\\n Hope, deceased prisoner, hails from Salt Lake City. If\\n case no other effect, brings out\\n efficiency of our detective police force will\\n serve as lesson to foreigners to settle\\n feuds at home not to carry them on to British soil.\\n open secret credit of smart capture belongs to\\n Scotland Yard officials, Messrs. Lestrade and Gregson.\\n\\nCHUNK 324\\n “Having left house, I proceeded to do what Gregson had neglected.\\n telegraphed to head of police at Cleveland limiting enquiry\\n to circumstances connected with marriage of Enoch Drebber.\\n answer conclusive. told Drebber had already applied for\\n protection of law against old rival in love, Jefferson\\n Hope, this same Hope was at present in Europe. knew now\\n held clue to mystery in hand, remained to\\n secure murderer.\\n\\nCHUNK 307\\n “That was how Enoch Drebber came to his end. All I had to do was\\n to do as much for Stangerson, pay off John Ferrier’s debt.\\n knew he was staying at Halliday’s Private Hotel hung about\\n all day, but he never came out. fancy he suspected something\\n when Drebber failed to put in appearance. He was cunning,\\nStangerson, always on his guard. If thought he could keep me off\\n by staying indoors was mistaken. I found out which\\n was window of his bedroom early next morning took advantage\\n of ladders in lane behind hotel\\n made my way into his room in grey of dawn. woke him up\\n told him hour had come he to answer for life he\\n taken long before. described Drebber’s death to him\\n gave him same choice of poisoned pills. Instead of grasping at\\n chance of safety he sprang from bed\\n\\nCHUNK 137\\n “I no objection,” Lestrade answered seating himself. “I\\n confess of opinion Stangerson was concerned in\\n death of Drebber. fresh development shown me I was\\n completely mistaken. Full of one idea set myself to find out\\n what had become of Secretary. They seen together at Euston\\n Station half-past eight on evening of third. At two in\\n morning Drebber found in Brixton Road. question\\n confronted to find out how Stangerson employed\\n between 8. 30 and time of crime what had become of him\\n afterwards. telegraphed to Liverpool giving description of\\n man warning them to keep watch upon American boats.\\n set to work calling upon hotels and lodging-houses in\\n vicinity of Euston. argued if Drebber and his companion\\n separated, natural course for latter would be to put\\n\\nCHUNK 268\\n “What has become of Lucy Ferrier?”\\n\\n “She was married yesterday to young Drebber. Hold up man\\n no life left in you. ”\\n\\n “Don’t mind me,” said Hope faintly. He was white to lips\\n sunk down on stone against he leaning. “Married,\\nyou say?”\\n\\n “Married yesterday—that’s flags for on Endowment\\n House. words between young Drebber and young Stangerson\\n to which to have her. both been in party\\n followed them Stangerson shot her father seemed to give\\n him best claim; argued in council, Drebber’s\\n party stronger Prophet gave her over to him. No one\\n won’t have her very long saw death in her face yesterday.\\n She more like a ghost than woman. Are you off, then?”'] \n",
      "\n",
      "reference_contexts: ['“The public,” it said, “have lost a sensational treat through the\\nsudden death of the man Hope, who was suspected of the murder of Mr.\\nEnoch Drebber and of Mr. Joseph Stangerson. The details of the case\\nwill probably be never known now, though we are informed upon good\\nauthority that the crime was the result of an old standing and romantic\\nfeud, in which love and Mormonism bore a part. It seems that both the\\nvictims belonged, in their younger days, to the Latter Day Saints, and\\nHope, the deceased prisoner, hails also from Salt Lake City. If the\\ncase has had no other effect, it, at least, brings out in the most\\nstriking manner the efficiency of our detective police force, and will\\nserve as a lesson to all foreigners that they will do wisely to settle\\ntheir feuds at home, and not to carry them on to British soil. It is an\\nopen secret that the credit of this smart capture belongs entirely to\\nthe well-known Scotland Yard officials, Messrs. Lestrade and Gregson.', '“What if we are stopped,” asked Ferrier.\\n\\nHope slapped the revolver butt which protruded from the front of his\\ntunic. “If they are too many for us we shall take two or three of them\\nwith us,” he said with a sinister smile.\\n\\nThe lights inside the house had all been extinguished, and from the\\ndarkened window Ferrier peered over the fields which had been his own,\\nand which he was now about to abandon for ever. He had long nerved\\nhimself to the sacrifice, however, and the thought of the honour and\\nhappiness of his daughter outweighed any regret at his ruined fortunes.\\nAll looked so peaceful and happy, the rustling trees and the broad\\nsilent stretch of grain-land, that it was difficult to realize that the\\nspirit of murder lurked through it all. Yet the white face and set\\nexpression of the young hunter showed that in his approach to the house\\nhe had seen enough to satisfy him upon that head.'] \n",
      "\n",
      "response: From the context, we can learn that Hope is a suspect in the murder case of Enoch Drebber and Joseph Stangerson. He is described as being white to lips sunk down on stone against he leaning, indicating he may be dying or very ill. The conversation with Lucy Ferrier's husband suggests that Hope was involved in a romantic feud and had a connection to the Latter Day Saints, which led to his involvement in the murder case.\n",
      "\n",
      "The context also touches on themes of hope and sacrifice, as Hope is described as being \"faintly\" speaking, implying he may be nearing death. The conversation with Lucy Ferrier's husband implies that Hope was willing to make sacrifices for his cause, but it is unclear what specific theme or message this is meant to convey.\n",
      "\n",
      "There are no clear contradictions between different sources in the context provided. \n",
      "\n",
      "reference: In the context of the murder case involving Enoch Drebber and Joseph Stangerson, the character Hope is depicted as a complex figure whose actions reflect themes of hope and sacrifice. The narrative reveals that Hope was suspected of the murders, which were tied to a romantic feud involving love and Mormonism. Despite the grim circumstances surrounding the case, Hope's determination to protect his daughter and his willingness to face danger suggest a deep sense of hope for her future, outweighing his own regrets about his ruined fortunes. His sinister smile when discussing potential violence indicates a readiness to confront threats, showcasing a blend of hope for a better outcome and the harsh realities of his situation. The juxtaposition of the peaceful landscape with the lurking spirit of murder further emphasizes the tension between hope and despair in this narrative. \n",
      "\n",
      "context_recall = 0.4\n",
      "llm_context_precision_with_reference = 0.9999999999\n",
      "llm_context_precision_without_reference = 0.9999999999\n",
      "answer_correctness = 0.4666121284664182\n",
      "answer_relevancy = 0.0\n",
      "semantic_similarity = 0.9064485138656728\n",
      "faithfulness = 0.9230769230769232\n"
     ]
    }
   ],
   "source": [
    "print_score_pd(scoreset_pd, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1695fb55-f7ed-49c1-87a1-e8d6337156c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_input: How does the reference to the Roman miser in 'A Study in Scarlet' reflect Sherlock Holmes' perspective on success? \n",
      "\n",
      "retrieved_contexts: ['From Sherlock_Study_in_Scarlet:\\n\\nCHUNK 330\\n “Didn’t I tell so when started?” cried Sherlock Holmes\\n laugh. result of our Study in Scarlet get\\n testimonial!”\\n\\n “Never mind I answered “I have facts in my journal\\n public shall know them. make yourself\\n contented by consciousness of success like Roman miser—\\n\\n\\n “‘Populus me sibilat plaudo\\n Ipse domi simul nummos contemplor in arca.\\n\\n\\n\\n\\n\\n\\n END OF PROJECT GUTENBERG EBOOK A STUDY IN SCARLET ***\\n\\n\\n\\n\\n Updated editions replace previous old editions\\n renamed.\\n\\nCHUNK\\n Project Gutenberg eBook of A Study in Scarlet\\n\\n ebook for use of anyone in United States\\n other parts of world at no cost almost no restrictions\\n. may copy give away re-use under terms\\n Project Gutenberg License online\\n at www. gutenberg. org. If not located in United States\\n check laws of country\\n before using eBook.\\n\\n Title: A Study in Scarlet\\n\\n Author: Arthur Conan Doyle\\n\\n Release date: April 1, 1995 [eBook #244]\\n recently updated: April 17, 2023\\n\\n Language: English\\n\\n Credits: Roger Squires and David Widger\\n\\n\\n START OF PROJECT GUTENBERG EBOOK A STUDY IN SCARLET ***\\n\\n\\n\\n\\n STUDY IN SCARLET\\n\\n By. Conan Doyle\\n\\n\\n\\n\\n CONTENTS\\n\\n STUDY IN SCARLET.\\n\\nCHUNK 17\\n “You are to be congratulated,” remarked surprised at\\n his enthusiasm.\\n\\n case of Von Bischoff at Frankfort last year. He would\\n have been hung had this test in existence.\\nMason of Bradford notorious Muller Lefevre of\\n Montpellier Samson of New Orleans. name score of cases\\n decisive.\\n\\n walking calendar of crime said Stamford\\n laugh. start paper on lines. Call ‘Police\\n News of the Past.\\n\\n interesting reading be made remarked Sherlock\\n Holmes sticking small piece plaster over prick on finger.\\n be careful continued turning to me smile\\n dabble with poisons good deal. held out hand spoke\\n noticed mottled over with similar pieces\\n plaster discoloured with strong acids.\\n\\nCHUNK\\n STUDY IN SCARLET\\n\\n By A. Conan Doyle\\n\\n\\n\\n\\n CONTENTS\\n\\n STUDY IN SCARLET.\\n\\n PART I.\\n CHAPTER I.. SHERLOCK HOLMES.\\n CHAPTER II. SCIENCE OF DEDUCTION.\\n CHAPTER III. LAURISTON GARDENS MYSTERY\\n CHAPTER IV. WHAT JOHN RANCE HAD TO TELL.\\n CHAPTER V. OUR ADVERTISEMENT BRINGS VISITOR.\\n CHAPTER VI. TOBIAS GREGSON SHOWS WHAT HE CAN DO.\\n CHAPTER VII. LIGHT IN THE DARKNESS.\\n\\n PART II. COUNTRY OF THE SAINTS\\n CHAPTER I. GREAT ALKALI PLAIN.\\n CHAPTER II. FLOWER OF UTAH.\\n CHAPTER III. JOHN FERRIER TALKS WITH PROPHET.\\n CHAPTER IV. FLIGHT FOR LIFE.\\n CHAPTER V. AVENGING ANGELS.\\n CHAPTER VI. CONTINUATION OF REMINISCENCES OF JOHN WATSON..\\n CHAPTER VII. CONCLUSION.\\n\\n\\n\\n\\nSTUDY IN SCARLET.\\n\\n\\n\\n\\n PART I.\\n\\n\\n ( reprint from Reminiscences of JOHN H. WATSON, M. D. \\n _Late of Army Medical Department. _)\\n\\n\\n\\n\\n CHAPTER I.\\n MR. SHERLOCK HOLMES.\\n\\nCHUNK 94\\n “The ring, man: he came back for. If no\\n other way of catching him bait our line with ring. I\\n shall have him, Doctor—I’ll lay you two to one have him.\\n thank you for it all. might not gone for you\\n missed finest study: study in scarlet?\\n use art jargon. scarlet thread of\\n murder running through colourless skein of life duty to\\n unravel it isolate it expose every inch of it. now for\\n lunch Norman Neruda. Her attack and bowing are\\n splendid. little thing of Chopin’s plays\\n magnificently: Tra-la-la-lira-lira-lay. ”\\n\\n Leaning back in cab amateur bloodhound carolled away like\\n lark while meditated upon many-sidedness of human mind.\\n\\n\\n\\n\\n CHAPTER V.\\n OUR ADVERTISEMENT BRINGS A VISITOR.'] \n",
      "\n",
      "reference_contexts: ['“Didn’t I tell you so when we started?” cried Sherlock Holmes with a\\nlaugh. “That’s the result of all our Study in Scarlet: to get them a\\ntestimonial!”\\n\\n“Never mind,” I answered, “I have all the facts in my journal, and the\\npublic shall know them. In the meantime you must make yourself\\ncontented by the consciousness of success, like the Roman miser—\\n\\n\\n“‘Populus me sibilat, at mihi plaudo\\nIpse domi simul ac nummos contemplor in arca.’”\\n\\n\\n\\n\\n\\n\\n*** END OF THE PROJECT GUTENBERG EBOOK A STUDY IN SCARLET ***\\n\\n\\n    \\n\\nUpdated editions will replace the previous one—the old editions will\\nbe renamed.'] \n",
      "\n",
      "response: The reference to the Roman miser in 'A Study in Scarlet' reflects Sherlock Holmes' perspective on success as a consciousness of success, implying that he finds satisfaction and fulfillment in his work, much like the Roman miser who is content with his wealth. \n",
      "\n",
      "reference: In 'A Study in Scarlet', Sherlock Holmes uses the reference to the Roman miser to illustrate a sense of satisfaction derived from personal success, despite external criticism. He likens the feeling of contentment he expects from their achievements to that of the Roman miser, who finds joy in counting his wealth at home, indifferent to the public's scorn. This comparison emphasizes Holmes' belief in the value of personal accomplishment over public opinion. \n",
      "\n",
      "context_recall = 1.0\n",
      "llm_context_precision_with_reference = 0.9999999999\n",
      "llm_context_precision_without_reference = 0.9999999999\n",
      "answer_correctness = 0.4729242776839716\n",
      "answer_relevancy = 0.9911783965842048\n",
      "semantic_similarity = 0.9686201876589636\n",
      "faithfulness = 0.25\n"
     ]
    }
   ],
   "source": [
    "print_score_pd(scoreset_pd, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb8087-ee1c-47f7-8bd5-e43e2560b322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

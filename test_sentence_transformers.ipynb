{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc026b82-9a66-45d7-9760-77d6555fda6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7077c03ab0c6410c9c8912f5d2812960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef2c574bc5147dfb8c7e98afee9ac8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d762315b49804e2e94cb5ed0d5b0a62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84831dde85af400d8ed3a5e2f82e7932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744e769709ce4a40abf2f80b14255e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59ce5c6f4414a3487dafa5e9a54cf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e4b6b40e254e0bba3be1a19a6f0282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cb58e6060e4c379509b77689d603bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2347976204514f3db078c843f0a47cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8aa032b7741464b87bf222f84ec9b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dddd7f52d04cfebdc2604393d897cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea10e4f3-4063-460f-ab93-6da72b825897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c6451036f84b6c8744a193da7f4ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6452e183af0d450bbe25e49a5d6c7345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05a248024a749caadcde44d3b240a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af25e931fbcf4e008211853bfce375fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0475bef4594882a616aa8a1fecfadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'corpus_id': 0,\n",
       "  'score': 10.678579,\n",
       "  'text': \"'To Kill a Mockingbird' is a novel by Harper Lee published in 1960. It was immediately successful, winning the Pulitzer Prize, and has become a classic of modern American literature.\"},\n",
       " {'corpus_id': 2,\n",
       "  'score': 9.761675,\n",
       "  'text': \"Harper Lee, an American novelist widely known for her novel 'To Kill a Mockingbird', was born in 1926 in Monroeville, Alabama. She received the Pulitzer Prize for Fiction in 1961.\"},\n",
       " {'corpus_id': 1,\n",
       "  'score': -3.3099546,\n",
       "  'text': \"The novel 'Moby-Dick' was written by Herman Melville and first published in 1851. It is considered a masterpiece of American literature and deals with complex themes of obsession, revenge, and the conflict between good and evil.\"},\n",
       " {'corpus_id': 5,\n",
       "  'score': -4.8989124,\n",
       "  'text': \"'The Great Gatsby', a novel written by American author F. Scott Fitzgerald, was published in 1925. The story is set in the Jazz Age and follows the life of millionaire Jay Gatsby and his pursuit of Daisy Buchanan.\"},\n",
       " {'corpus_id': 4,\n",
       "  'score': -5.082966,\n",
       "  'text': \"The 'Harry Potter' series, which consists of seven fantasy novels written by British author J.K. Rowling, is among the most popular and critically acclaimed books of the modern era.\"},\n",
       " {'corpus_id': 3,\n",
       "  'score': -6.4780054,\n",
       "  'text': 'Jane Austen was an English novelist known primarily for her six major novels, which interpret, critique and comment upon the British landed gentry at the end of the 18th century.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "query = \"Who wrote 'To Kill a Mockingbird'?\"\n",
    "documents = [\n",
    "    \"'To Kill a Mockingbird' is a novel by Harper Lee published in 1960. It was immediately successful, winning the Pulitzer Prize, and has become a classic of modern American literature.\",\n",
    "    \"The novel 'Moby-Dick' was written by Herman Melville and first published in 1851. It is considered a masterpiece of American literature and deals with complex themes of obsession, revenge, and the conflict between good and evil.\",\n",
    "    \"Harper Lee, an American novelist widely known for her novel 'To Kill a Mockingbird', was born in 1926 in Monroeville, Alabama. She received the Pulitzer Prize for Fiction in 1961.\",\n",
    "    \"Jane Austen was an English novelist known primarily for her six major novels, which interpret, critique and comment upon the British landed gentry at the end of the 18th century.\",\n",
    "    \"The 'Harry Potter' series, which consists of seven fantasy novels written by British author J.K. Rowling, is among the most popular and critically acclaimed books of the modern era.\",\n",
    "    \"'The Great Gatsby', a novel written by American author F. Scott Fitzgerald, was published in 1925. The story is set in the Jazz Age and follows the life of millionaire Jay Gatsby and his pursuit of Daisy Buchanan.\"\n",
    "]\n",
    "\n",
    "model.rank(query, documents, return_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4d84e8b-661e-4997-91f9-918a6728474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import weaviate\n",
    "from weaviate.classes.data import DataObject\n",
    "from weaviate.classes.config import Configure, VectorDistances\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import weaviate.classes.query as wq\n",
    "from weaviate.classes.query import Filter\n",
    "from weaviate.classes.query import Rerank, MetadataQuery\n",
    "from weaviate.classes.config import Property, DataType\n",
    "\n",
    "ollama_url = 'localhost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "59b014f4-5de0-42ce-a96d-4ab8c06ea5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooksProcessor:\n",
    "    def __init__(self, ollama_url: str = 'localhost', embedding_model_name:str = 'nomic-embed-text',\n",
    "                 wv_port_rest: int = 8080, wv_port_grpc: int = 50051):\n",
    "        self.embedding_model_name = embedding_model_name\n",
    "        self.wv_client = weaviate.connect_to_local(\n",
    "            host=ollama_url,\n",
    "            port=wv_port_rest,\n",
    "            grpc_port=wv_port_grpc,\n",
    "        )\n",
    "        print(f\"Connected to Weaviate: {self.wv_client.is_ready()}\")\n",
    "        self.big_chunks = self.create_collection_if_not_exists('big_chunks')\n",
    "        self.medium_chunks = self.create_collection_if_not_exists('medium_chunks')\n",
    "        self.small_chunks = self.create_collection_if_not_exists('small_chunks')\n",
    "\n",
    "\n",
    "    def create_collection_if_not_exists(self, collection_name: str):\n",
    "        # Проверка наличия коллекции\n",
    "        print(self.wv_client.collections)\n",
    "        if self.wv_client.collections.exists(collection_name):\n",
    "            print(f\"Getting '{collection_name}'\")\n",
    "        else:\n",
    "            print(f\"Creating '{collection_name}'\")\n",
    "\n",
    "            # Создать коллекцию с привязанным векторизатором. Два варианта векторизаторов\n",
    "            book_chunks = self.wv_client.collections.create(\n",
    "                name=collection_name,\n",
    "                properties=[Property(name=\"chunk\", data_type=DataType.TEXT),\n",
    "                            Property(name=\"book_name\", data_type=DataType.TEXT),\n",
    "                            Property(name=\"chunk_num\", data_type=DataType.INT)],\n",
    "                \n",
    "                vectorizer_config=[\n",
    "                    Configure.NamedVectors.text2vec_ollama(\n",
    "                        name=\"book_vectorizer\",\n",
    "                        source_properties=[\"book_chunks\"],\n",
    "                        api_endpoint=\"http://ollama:11434\",\n",
    "                        model=self.embedding_model_name,\n",
    "                        vector_index_config=Configure.VectorIndex.hnsw(distance_metric=VectorDistances.COSINE))\n",
    "                ]\n",
    "            )\n",
    "        return self.wv_client.collections.get(collection_name)\n",
    "\n",
    "    def check_book_exists(self, book_name: str):\n",
    "        book_filter = Filter.by_property(\"book_name\").equal(book_name)\n",
    "        \n",
    "        # Выполняем запрос\n",
    "        result = self.big_chunks.query.fetch_objects(\n",
    "            filters=book_filter,\n",
    "            limit=1\n",
    "        )\n",
    "        return result.objects\n",
    "\n",
    "    def split_book(self, book_text: str, chunk_size: int, chunk_overlap: int):\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,  # Максимальный размер чанка\n",
    "            chunk_overlap=chunk_overlap  # Перекрытие между чанками\n",
    "        )\n",
    "        return splitter.create_documents([book_text])      \n",
    "\n",
    "    def send_to_db(self, collection, chunks, book_name):\n",
    "        with collection.batch.fixed_size(batch_size=10) as batch:\n",
    "            for i, d in enumerate(chunks):\n",
    "                batch.add_object({\n",
    "                    \"chunk\": d.page_content,\n",
    "                    \"book_name\": book_name,\n",
    "                    \"chunk_num\": int(i)\n",
    "                })\n",
    "\n",
    "    def delete_book(self, collection_name: str):\n",
    "        book_filter = Filter.by_property(\"book_name\").equal(collection_name)\n",
    "        \n",
    "        # Выполнение пакетного удаления\n",
    "        response_big = self.big_chunks.data.delete_many(\n",
    "            where=book_filter\n",
    "        )\n",
    "        \n",
    "        # Выполнение пакетного удаления\n",
    "        response_medium = self.medium_chunks.data.delete_many(\n",
    "            where=book_filter\n",
    "        )\n",
    "\n",
    "        # Выполнение пакетного удаления\n",
    "        response_small = self.small_chunks.data.delete_many(\n",
    "            where=book_filter\n",
    "        )\n",
    "        \n",
    "        # Проверка результата\n",
    "        if response_small.successful > 0:\n",
    "            print(f\"Successfully deleted {response_big.successful}, {response_medium.successful}, {response_small.successful} objects.\")\n",
    "        else:\n",
    "            print(\"Nothing to delete\")\n",
    "    \n",
    "    def process_book(self, book_name: str, book_txt: str):\n",
    "        if self.check_book_exists(book_name):\n",
    "            print(\"Book already exists\")\n",
    "            return\n",
    "        else:\n",
    "            print(\"Processing book\")\n",
    "\n",
    "        big_chunks = self.split_book(book_txt, 3000, 1000)\n",
    "        self.send_to_db(collection=self.big_chunks, chunks=big_chunks, book_name=book_name)\n",
    "\n",
    "        medium_chunks = self.split_book(book_txt, 1500, 500)\n",
    "        self.send_to_db(collection=self.medium_chunks, chunks=medium_chunks, book_name=book_name)\n",
    "\n",
    "        small_chunks = self.split_book(book_txt, 750, 250)\n",
    "        self.send_to_db(collection=self.small_chunks, chunks=small_chunks, book_name=book_name)\n",
    "        \n",
    "        print(\"Book successfully processed\")\n",
    "\n",
    "\n",
    "class Sear\n",
    "    def __init__(self, ollama_url: str = 'localhost', llm_name:str = 'Llama3.2',\n",
    "                 wv_port_rest: int = 8080, wv_port_grpc: int = 50051):\n",
    "        self.llm = OllamaLLM(model=llm_name, temperature=0, base_url=f\"{ollama_url}:11434\")\n",
    "        self.wv_client = weaviate.connect_to_local(\n",
    "            host=ollama_url,\n",
    "            port=wv_port_rest,\n",
    "            grpc_port=wv_port_grpc,\n",
    "        )\n",
    "        print(f\"Connected to Weaviate: {self.wv_client.is_ready()}\")\n",
    "\n",
    "    def search(query: str):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2321160a-077e-4472-b7f8-587cc225aeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Weaviate: True\n",
      "<weaviate.collections.collections.sync._Collections object at 0x79d82d7faba0>\n",
      "Getting 'big_chunks'\n",
      "<weaviate.collections.collections.sync._Collections object at 0x79d82d7faba0>\n",
      "Getting 'medium_chunks'\n",
      "<weaviate.collections.collections.sync._Collections object at 0x79d82d7faba0>\n",
      "Getting 'small_chunks'\n"
     ]
    }
   ],
   "source": [
    "books_processor = BooksProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08547b21-cfac-4bca-8589-0ed886ca5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alice_in_wonderland.txt', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d173deeb-ce5b-4a03-a0ab-ad998ca45134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing book\n",
      "Book successfully processed\n"
     ]
    }
   ],
   "source": [
    "books_processor.process_book('alice in wonderland', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fce26adc-0c8a-450f-8282-aea4b5d7bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deleted 75, 147, 287 objects.\n"
     ]
    }
   ],
   "source": [
    "#books_processor.delete_book('alice in wonderland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af491568-77f9-41ba-bb93-ee002c190e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import BaseLLM\n",
    "from enum import Enum\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "class ChunkSize(Enum):\n",
    "    SMALL = {\"size\": 500, \"overlap\": 50}\n",
    "    MEDIUM = {\"size\": 1000, \"overlap\": 100}\n",
    "    LARGE = {\"size\": 2000, \"overlap\": 200}\n",
    "\n",
    "class ChunkClassifier:\n",
    "    def __init__(self, llm: BaseLLM):\n",
    "        with open('prompt.j2') as f:\n",
    "            template = f.read()\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=template\n",
    "        )\n",
    "        self.llm = llm\n",
    "\n",
    "    def get_chunk_params(self, query: str) -> Dict[str, int]:\n",
    "        prompt = self.prompt.format(query=query)\n",
    "        response = self.llm.predict(prompt).strip().upper()\n",
    "        try:\n",
    "            return ChunkSize[response].value\n",
    "        except KeyError:\n",
    "            return ChunkSize.MEDIUM.value\n",
    "\n",
    "# Пример использования:\n",
    "\"\"\"\n",
    "classifier = ChunkClassifier(llm=llm)\n",
    "params = classifier.get_chunk_params(\"В чем основная идея книги?\")\n",
    "# Вернет: {'size': 2000, 'overlap': 200}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a13cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d2ebeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I don't have personal feelings or emotions like humans do, but I can certainly chat with you about cats if you'd like! Many people adore cats and their unique personalities, independence, and adorable antics. What's your relationship like with cats? Do you have a feline friend at home?\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaLLM(model=\"llama3.2\", temperature=1)\n",
    "response = llm.invoke(\"hi, do u love cats\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79307bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.19043786, 0.27984475],\n",
       "       [0.19043786, 1.        , 0.68144236],\n",
       "       [0.27984475, 0.68144236, 1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"all-minilm:33m\")\n",
    "\n",
    "texts = [\n",
    "    \"–ß—Ç–æ —Ç–∞–∫–æ–µ LangChain?\",\n",
    "    \"–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Ollama –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤?\",\n",
    "    \"–ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Ollama?\"\n",
    "]\n",
    "\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "\n",
    "vectors = np.array(vectors)\n",
    "new_matr = vectors/np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "new_matr @ new_matr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23da6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "from weaviate.classes.config import Configure\n",
    "from weaviate.classes.query import MetadataQuery\n",
    "import requests, json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbf243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "client = weaviate.connect_to_local()\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc657bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58979678",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = client.collections.create(\n",
    "    name=\"Question\",\n",
    "    #vectorizer_config=Configure.Vectorizer.text2vec_ollama(     # Configure the Ollama embedding integration\n",
    "    #    api_endpoint=\"http://ollama:11434\",       # Allow Weaviate from within a Docker container to contact your Ollama instance\n",
    "    #    model=\"all-minilm:33m\",                              # The model to use\n",
    "    #),\n",
    "    vectorizer_config =[\n",
    "        Configure.NamedVectors.text2vec_ollama(\n",
    "            name=\"title_vector\",\n",
    "            source_properties=[\"answer\"],\n",
    "            api_endpoint=\"http://ollama:11434\",  # If using Docker, use this to contact your local Ollama instance\n",
    "            model=\"all-minilm:33m\",  # The model to use, e.g. \"nomic-embed-text\"\n",
    "    )\n",
    "    ],\n",
    "    generative_config=Configure.Generative.ollama(              # Configure the Ollama generative integration\n",
    "        api_endpoint=\"http://ollama:11434\",       # Allow Weaviate from within a Docker container to contact your Ollama instance\n",
    "        model=\"llama3.2\",                                       # The model to use\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8676013",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\n",
    "    \"https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json\"\n",
    ")\n",
    "data = json.loads(resp.text)\n",
    "\n",
    "questions = client.collections.get(\"Question\")\n",
    "\n",
    "with questions.batch.dynamic() as batch:\n",
    "    for d in data:\n",
    "        batch.add_object({\n",
    "            \"answer\": d[\"Answer\"],\n",
    "            \"question\": d[\"Question\"],\n",
    "            \"category\": d[\"Category\"],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fad657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"answer\": \"species\",\n",
      "  \"question\": \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a new one of this classification\",\n",
      "  \"category\": \"SCIENCE\"\n",
      "}\n",
      "{\n",
      "  \"answer\": \"Elephant\",\n",
      "  \"question\": \"It's the only living mammal in the order Proboseidea\",\n",
      "  \"category\": \"ANIMALS\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "questions = client.collections.get(\"Question\")\n",
    "\n",
    "response = questions.query.near_text(\n",
    "    query=\"mammal\",\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(json.dumps(obj.properties, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7904917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"üåøü¶å Did you know? ü§î The Gunnison sage grouse is a unique species in its own right! üêì And get ready for some serious horns: the eland in Africa can weigh up to 1 ton, making it the largest of its kind! üòÆ #WildlifeFacts #Science #AnimalLovers\"\n"
     ]
    }
   ],
   "source": [
    "questions = client.collections.get(\"Question\")\n",
    "\n",
    "response = questions.generate.near_text(\n",
    "    query=\"species\",\n",
    "    limit=2,\n",
    "    grouped_task=\"Write a tweet with emojis about these facts.\"\n",
    ")\n",
    "\n",
    "print(response.generated)  # Inspect the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a8573e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11311cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
